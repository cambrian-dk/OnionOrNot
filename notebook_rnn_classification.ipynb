{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOUwS5OiNcDCJU4J34VgRQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "44dcbaea3c3e4bcf8451432f8d654ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad2ff9e9be644721adb9aa61d5dc985d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1c88cd6cfe6f4f8b954549b58ffa794e",
              "IPY_MODEL_b27e1d07ce6a43a2b2db048e763e5772"
            ]
          }
        },
        "ad2ff9e9be644721adb9aa61d5dc985d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c88cd6cfe6f4f8b954549b58ffa794e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b467ffea1b6c4b91be09ab3a2226506c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 68898,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 68898,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_694aa9dffc66490090acdb4b72232a34"
          }
        },
        "b27e1d07ce6a43a2b2db048e763e5772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97f3c3b419ee40f7ac928eeb768d7a86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 68898/68898 [01:50&lt;00:00, 625.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_359f42629dda43379f776cb847846685"
          }
        },
        "b467ffea1b6c4b91be09ab3a2226506c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "694aa9dffc66490090acdb4b72232a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97f3c3b419ee40f7ac928eeb768d7a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "359f42629dda43379f776cb847846685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94b9cea50e5649fdb7b14362b484b9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40fb5cb19cf14d51a61aa4ab978d901c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_234992681a734d1295e95f2cd1d96ef7",
              "IPY_MODEL_38b46cf47db2496ea5e6303ddb4ede85"
            ]
          }
        },
        "40fb5cb19cf14d51a61aa4ab978d901c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "234992681a734d1295e95f2cd1d96ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6811957fc8894499a9c9e721e155b089",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 34364,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 34364,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c47e8e47e9e4903817a86487156113c"
          }
        },
        "38b46cf47db2496ea5e6303ddb4ede85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06ec0717c27b40d889de4eeab98b9bd7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 34364/34364 [01:31&lt;00:00, 377.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef00115d0e6042378e3df0425c458ab4"
          }
        },
        "6811957fc8894499a9c9e721e155b089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c47e8e47e9e4903817a86487156113c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06ec0717c27b40d889de4eeab98b9bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef00115d0e6042378e3df0425c458ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nordic96/OnionOrNot/blob/main/notebook_rnn_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyiLetgWliHC"
      },
      "source": [
        "# Using Recursive Neural Network (RNN) - LSTM (Long Short Term Memory) Model for Satir News Headline Classification\n",
        "\n",
        "\n",
        "This notebook is created to explore the RNN approach for CS4248 Natural Language Processing (NLP) project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW-66Apwmjbl"
      },
      "source": [
        "## 1. Checking if GPU is enabled in Google Colab Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgoipDnzPQcx",
        "outputId": "613c0583-b9c8-453c-d5c5-a212a92804d3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 12 05:46:38 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOsjwZ4gJ30I"
      },
      "source": [
        "## Necessary Imports for RNN model training\n",
        "Reference taken from [online](https://jovian.ai/aakanksha-ns/lstm-multiclass-text-classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4stzBguPTDy",
        "outputId": "bc48078b-cae2-42fb-ffa8-795cefb4ddb2"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import nltk\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "from collections import Counter\n",
        "from torchsummary import summary\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyBY4zRgmzZA"
      },
      "source": [
        "## Mounting with Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atg97Ecajwu1",
        "outputId": "bc0a634b-0ce2-4589-e657-35ef05c7c745"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2zpzMBGm3Fd"
      },
      "source": [
        "## Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRmvVAUQjsfM"
      },
      "source": [
        "DATA_DIR = 'drive/MyDrive/datasets/'\n",
        "X = np.load(os.path.join(DATA_DIR, 'merged_dataset_X.npy'))\n",
        "y = np.load(os.path.join(DATA_DIR, 'merged_dataset_y.npy'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPis9m58nBJE"
      },
      "source": [
        "### Tokenisation & Lemmatization\n",
        "We now have a dataset of raw text (news headlines) with labels:\n",
        "1. 0: Not Onion (True News Headline)\n",
        "1. 1: Onion (Satire News Headline)\n",
        "1. 2: Fake (Not Onion)\n",
        "\n",
        "We then process the text data to a list of tokens, and lemmatise any changed form of text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9WFJrV7h29P"
      },
      "source": [
        "#tokenization & lemmatization\n",
        "def preprocess_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokenized = word_tokenize(text)\n",
        "    return [lemmatizer.lemmatize(token) for token in tokenized]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oshhozuAjIvN",
        "outputId": "b673f01e-d00a-408e-f7d3-35449aa1cada"
      },
      "source": [
        "#Checking if tokenisation and vlaidation is working\n",
        "preprocess_text(\"Ravioli, Ravioli, what's in the pocketoli\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ravioli', ',', 'Ravioli', ',', 'what', \"'s\", 'in', 'the', 'pocketoli']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCFmXuy1oOqz"
      },
      "source": [
        "### Creating Vocabulary of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "44dcbaea3c3e4bcf8451432f8d654ad1",
            "ad2ff9e9be644721adb9aa61d5dc985d",
            "1c88cd6cfe6f4f8b954549b58ffa794e",
            "b27e1d07ce6a43a2b2db048e763e5772",
            "b467ffea1b6c4b91be09ab3a2226506c",
            "694aa9dffc66490090acdb4b72232a34",
            "97f3c3b419ee40f7ac928eeb768d7a86",
            "359f42629dda43379f776cb847846685"
          ]
        },
        "id": "9jeAJ9zfjlIB",
        "outputId": "dfac3363-958c-46a7-e0a6-c8905f499366"
      },
      "source": [
        "#count number of occurences of each word\n",
        "counts = Counter()\n",
        "for sentence in tqdm_notebook(X):\n",
        "    counts.update(preprocess_text(sentence))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44dcbaea3c3e4bcf8451432f8d654ad1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=68898.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M4JPrTxlJAG",
        "outputId": "52f10bb1-6915-447f-b210-d361e5c3580a"
      },
      "source": [
        "#deleting infrequent words\n",
        "print(\"num_words before:\",len(counts.keys()))\n",
        "for word in list(counts):\n",
        "    if counts[word] < 2:\n",
        "        del counts[word]\n",
        "print(\"num_words after:\",len(counts.keys()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_words before: 57326\n",
            "num_words after: 34364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "94b9cea50e5649fdb7b14362b484b9f3",
            "40fb5cb19cf14d51a61aa4ab978d901c",
            "234992681a734d1295e95f2cd1d96ef7",
            "38b46cf47db2496ea5e6303ddb4ede85",
            "6811957fc8894499a9c9e721e155b089",
            "1c47e8e47e9e4903817a86487156113c",
            "06ec0717c27b40d889de4eeab98b9bd7",
            "ef00115d0e6042378e3df0425c458ab4"
          ]
        },
        "id": "HUpVgKtIl02B",
        "outputId": "0b0b41af-c8b8-4ed5-eb31-443a54beb301"
      },
      "source": [
        "#creating vocabulary\n",
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in tqdm_notebook(counts):\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94b9cea50e5649fdb7b14362b484b9f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=34364.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xlMu0hrmIXm",
        "outputId": "b939bf08-f31d-4a85-87e4-1c3aea685c97"
      },
      "source": [
        "#Checking max length from the entire news dataset\n",
        "max(map(lambda x: len(preprocess_text(x)), X))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdaw7gRQooph"
      },
      "source": [
        "### Encoding the entire dataset with customised vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbac8JyemD11"
      },
      "source": [
        "def encode_sentence(text, vocab2index, N=79):\n",
        "    tokenized = preprocess_text(text)\n",
        "    encoded = np.zeros(N, dtype=int)\n",
        "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
        "    length = min(N, len(enc1))\n",
        "    encoded[:length] = enc1[:length]\n",
        "    return encoded, length"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFYpg2cVnMd6"
      },
      "source": [
        "X_encoded = [encode_sentence(x, vocab2index) for x in X]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RRilcSeoWb_"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = np.array(X, dtype=object)\n",
        "        self.y = np.array(y).astype(np.int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyfPkcwvpDHc",
        "outputId": "7574e3e7-3375-4867-b932-a397a9d4fbbc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25, random_state=42)\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51673\n",
            "17225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pit5oiadouuY"
      },
      "source": [
        "## Defining the Neural Network Model\n",
        "Now the dataset is prepared, we need to create the RNN model for training. LSTM layer is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcCQEcVRPbQt"
      },
      "source": [
        "class LSTM_variable_input(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.embeddings = torch.nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = torch.nn.Linear(hidden_dim, 5)\n",
        "        \n",
        "    def forward(self, x, s):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
        "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
        "        out = self.linear(ht[-1])\n",
        "        return out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzd9kQqYpYhh"
      },
      "source": [
        "## Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq-Jxuv-PyxY"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def train_model(model, epochs=10, lr=0.001):\n",
        "    train_acc_list = []\n",
        "    train_loss_list = []\n",
        "    val_acc_list = []\n",
        "    val_loss_list = []\n",
        "\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        count = 0\n",
        "        correct = 0\n",
        "        for x, y, l in train_dl:\n",
        "            count += 1\n",
        "            x = x.long().cuda()\n",
        "            y = y.long().cuda()\n",
        "            y_pred = model(x, l)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.cross_entropy(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "\n",
        "            _, predicted = torch.max(y_pred, 1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.shape[0]\n",
        "            accuracy = 100 * correct / total\n",
        "            print('[epoch: %5d/%5d, batch: %5d] loss: %.3f, lr: %.10f, acc %d %%'% (i, epochs, count, loss.clone().item(), get_lr(optimizer), accuracy))\n",
        "        train_acc_list.append(accuracy)\n",
        "        train_loss_list.append(sum_loss / total)\n",
        "        \n",
        "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
        "        val_acc_list.append(val_acc.cpu() * 100)\n",
        "        val_loss_list.append(val_loss)\n",
        "        print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
        "    return train_acc_list, val_acc_list, train_loss_list, val_loss_list\n",
        "\n",
        "def validation_metrics (model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    for x, y, l in valid_dl:\n",
        "        x = x.long().cuda()\n",
        "        y = y.long().cuda()\n",
        "        y_hat = model(x, l)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = torch.max(y_hat, 1)[1]\n",
        "        correct += (pred == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "\n",
        "        mse = mean_squared_error(pred.cpu(), y.unsqueeze(-1).cpu())\n",
        "        sum_rmse += np.sqrt(mse)*y.shape[0]\n",
        "    return sum_loss/total, correct/total, sum_rmse/total"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGkIUlrbpgL8"
      },
      "source": [
        "## Execution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqRZ-l-hz5sT"
      },
      "source": [
        "train_dataset = NewsDataset(X_train, y_train)\n",
        "val_dataset = NewsDataset(X_test, y_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDv5-unS1nq9"
      },
      "source": [
        "hidden_dim_size = 79\n",
        "vocab_size = len(words)\n",
        "model = LSTM_variable_input(vocab_size=vocab_size, embedding_dim=79, hidden_dim=hidden_dim_size)\n",
        "model = model.cuda().float()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MMrG_Hn1MEF"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dl = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=2, persistent_workers=False)\n",
        "val_dl = DataLoader(val_dataset, batch_size=128)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpaaL_7LLstE"
      },
      "source": [
        "IMG_DIR = 'drive/MyDrive/images'\n",
        "NUM_EPOCH = 30"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-tlEgXs6vIc",
        "outputId": "5f76fe6c-645a-41d3-d6f1-618587f503ba"
      },
      "source": [
        "train_acc_list, val_acc_list, train_loss_list, val_loss_list = train_model(model, epochs=NUM_EPOCH)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[epoch:    17/   30, batch:   266] loss: 0.044, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   267] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   268] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   269] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   270] loss: 0.048, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   271] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   272] loss: 0.035, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   273] loss: 0.058, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   274] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   275] loss: 0.035, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   276] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   277] loss: 0.044, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   278] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   279] loss: 0.085, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   280] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   281] loss: 0.006, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   282] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   283] loss: 0.006, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   284] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   285] loss: 0.072, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   286] loss: 0.055, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   287] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   288] loss: 0.059, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   289] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   290] loss: 0.056, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   291] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   292] loss: 0.044, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   293] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   294] loss: 0.077, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   295] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   296] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   297] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   298] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   299] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   300] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   301] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   302] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   303] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   304] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   305] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   306] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   307] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   308] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   309] loss: 0.066, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   310] loss: 0.078, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   311] loss: 0.044, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   312] loss: 0.059, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   313] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   314] loss: 0.097, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   315] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   316] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   317] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   318] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   319] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   320] loss: 0.046, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   321] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   322] loss: 0.086, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   323] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   324] loss: 0.090, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   325] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   326] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   327] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   328] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   329] loss: 0.004, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   330] loss: 0.003, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   331] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   332] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   333] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   334] loss: 0.035, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   335] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   336] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   337] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   338] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   339] loss: 0.006, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   340] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   341] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   342] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   343] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   344] loss: 0.053, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   345] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   346] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   347] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   348] loss: 0.078, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   349] loss: 0.089, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   350] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   351] loss: 0.039, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   352] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   353] loss: 0.076, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   354] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   355] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   356] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   357] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   358] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   359] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   360] loss: 0.043, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   361] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   362] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   363] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   364] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   365] loss: 0.047, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   366] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   367] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   368] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   369] loss: 0.047, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   370] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   371] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   372] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   373] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   374] loss: 0.064, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   375] loss: 0.068, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   376] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   377] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   378] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   379] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   380] loss: 0.047, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   381] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   382] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   383] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   384] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   385] loss: 0.004, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   386] loss: 0.062, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   387] loss: 0.070, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   388] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   389] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   390] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   391] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   392] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   393] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   394] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   395] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   396] loss: 0.062, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   397] loss: 0.047, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   398] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   399] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   400] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   401] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   402] loss: 0.037, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   403] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    17/   30, batch:   404] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "train loss 0.030, val loss 0.201, val accuracy 0.950, and val rmse 0.290\n",
            "[epoch:    18/   30, batch:     1] loss: 0.007, lr: 0.0010000000, acc 100 %\n",
            "[epoch:    18/   30, batch:     2] loss: 0.070, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:     3] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:     4] loss: 0.067, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:     5] loss: 0.023, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:     6] loss: 0.098, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:     7] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:     8] loss: 0.058, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:     9] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    10] loss: 0.039, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    11] loss: 0.070, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    12] loss: 0.053, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    13] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    14] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    15] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    16] loss: 0.043, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    17] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    18] loss: 0.037, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    19] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    20] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    21] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    22] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    23] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    24] loss: 0.063, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    25] loss: 0.072, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    26] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    27] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    28] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    29] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    30] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    31] loss: 0.003, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    32] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    33] loss: 0.006, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    34] loss: 0.074, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    35] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    36] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    37] loss: 0.083, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    38] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    39] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    40] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    41] loss: 0.046, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    42] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    43] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    44] loss: 0.006, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    45] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    46] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    47] loss: 0.006, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    48] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    49] loss: 0.061, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    50] loss: 0.063, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    51] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    52] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    53] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    54] loss: 0.072, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    55] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    56] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    57] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    58] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    59] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    60] loss: 0.079, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    61] loss: 0.059, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    62] loss: 0.038, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    63] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    64] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    65] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    66] loss: 0.053, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    67] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    68] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    69] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    70] loss: 0.003, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    71] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    72] loss: 0.053, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    73] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    74] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    75] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    76] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    77] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    78] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    79] loss: 0.044, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    80] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    81] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    82] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    83] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    84] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    85] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    86] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    87] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    88] loss: 0.062, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    89] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    90] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    91] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    92] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    93] loss: 0.067, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    94] loss: 0.003, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    95] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    96] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    97] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    98] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:    99] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   100] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   101] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   102] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   103] loss: 0.056, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   104] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   105] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   106] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   107] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   108] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   109] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   110] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   111] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   112] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   113] loss: 0.043, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   114] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   115] loss: 0.083, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   116] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   117] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   118] loss: 0.038, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   119] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   120] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   121] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   122] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   123] loss: 0.049, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   124] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   125] loss: 0.104, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   126] loss: 0.004, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   127] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   128] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   129] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   130] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   131] loss: 0.095, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   132] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   133] loss: 0.058, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   134] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   135] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   136] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   137] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   138] loss: 0.065, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   139] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   140] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   141] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   142] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   143] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   144] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   145] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   146] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   147] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   148] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   149] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   150] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   151] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   152] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   153] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   154] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   155] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   156] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   157] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   158] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   159] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   160] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   161] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   162] loss: 0.064, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   163] loss: 0.004, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   164] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   165] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   166] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   167] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   168] loss: 0.051, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   169] loss: 0.058, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   170] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   171] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   172] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   173] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   174] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   175] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   176] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   177] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   178] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   179] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   180] loss: 0.006, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   181] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   182] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   183] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   184] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   185] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   186] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   187] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   188] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   189] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   190] loss: 0.037, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   191] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   192] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   193] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   194] loss: 0.035, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   195] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   196] loss: 0.062, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   197] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   198] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   199] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   200] loss: 0.048, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   201] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   202] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   203] loss: 0.057, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   204] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   205] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   206] loss: 0.076, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   207] loss: 0.062, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   208] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   209] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   210] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   211] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   212] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   213] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   214] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   215] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   216] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   217] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   218] loss: 0.049, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   219] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   220] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   221] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   222] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   223] loss: 0.003, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   224] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   225] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   226] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   227] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   228] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   229] loss: 0.023, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   230] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   231] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   232] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   233] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   234] loss: 0.087, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   235] loss: 0.037, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   236] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   237] loss: 0.091, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   238] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   239] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   240] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   241] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   242] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   243] loss: 0.076, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   244] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   245] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   246] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   247] loss: 0.048, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   248] loss: 0.043, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   249] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   250] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   251] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   252] loss: 0.052, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   253] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   254] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   255] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   256] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   257] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   258] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   259] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   260] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   261] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   262] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   263] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   264] loss: 0.003, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   265] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   266] loss: 0.046, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   267] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   268] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   269] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   270] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   271] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   272] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   273] loss: 0.062, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   274] loss: 0.089, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   275] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   276] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   277] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   278] loss: 0.035, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   279] loss: 0.093, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   280] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   281] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   282] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   283] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   284] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   285] loss: 0.091, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   286] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   287] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   288] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   289] loss: 0.046, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   290] loss: 0.070, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   291] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   292] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   293] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   294] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   295] loss: 0.061, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   296] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   297] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   298] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   299] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   300] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   301] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   302] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   303] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   304] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   305] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   306] loss: 0.076, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   307] loss: 0.046, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   308] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   309] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   310] loss: 0.049, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   311] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   312] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   313] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   314] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   315] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   316] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   317] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   318] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   319] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   320] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   321] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   322] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   323] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   324] loss: 0.067, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   325] loss: 0.043, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   326] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   327] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   328] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   329] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   330] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   331] loss: 0.038, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   332] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   333] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   334] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   335] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   336] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   337] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   338] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   339] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   340] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   341] loss: 0.023, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   342] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   343] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   344] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   345] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   346] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   347] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   348] loss: 0.054, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   349] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   350] loss: 0.009, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   351] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   352] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   353] loss: 0.104, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   354] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   355] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   356] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   357] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   358] loss: 0.037, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   359] loss: 0.050, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   360] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   361] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   362] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   363] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   364] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   365] loss: 0.049, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   366] loss: 0.048, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   367] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   368] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   369] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   370] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   371] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   372] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   373] loss: 0.038, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   374] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   375] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   376] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   377] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   378] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   379] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   380] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   381] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   382] loss: 0.004, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   383] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   384] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   385] loss: 0.004, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   386] loss: 0.038, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   387] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   388] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   389] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   390] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   391] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   392] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   393] loss: 0.059, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   394] loss: 0.016, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   395] loss: 0.040, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   396] loss: 0.043, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   397] loss: 0.026, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   398] loss: 0.032, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   399] loss: 0.013, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   400] loss: 0.037, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   401] loss: 0.038, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   402] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   403] loss: 0.086, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    18/   30, batch:   404] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "train loss 0.029, val loss 0.211, val accuracy 0.951, and val rmse 0.289\n",
            "[epoch:    19/   30, batch:     1] loss: 0.010, lr: 0.0010000000, acc 100 %\n",
            "[epoch:    19/   30, batch:     2] loss: 0.081, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:     3] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:     4] loss: 0.035, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    19/   30, batch:     5] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:     6] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:     7] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:     8] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:     9] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    10] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    11] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    12] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    13] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    14] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    15] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    16] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    17] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    18] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    19] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    20] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    21] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    22] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    23] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    24] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    25] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    26] loss: 0.071, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    27] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    28] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    29] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    30] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    31] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    32] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    33] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    34] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    35] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    36] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    37] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    38] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    39] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    40] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    41] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    42] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    43] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    44] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    45] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    46] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    47] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    48] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    49] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    50] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    51] loss: 0.081, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    52] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    53] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    54] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    55] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    56] loss: 0.075, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    57] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    58] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    59] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    60] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    61] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    62] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    63] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    64] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    65] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    66] loss: 0.053, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    67] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    68] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    69] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    70] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    71] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    72] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    73] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    74] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    75] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    76] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    77] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    78] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    79] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    80] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    81] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    82] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    83] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    84] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    85] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    86] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    87] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    88] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    89] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    90] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    91] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    92] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    93] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    94] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    95] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    96] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    97] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    98] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:    99] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   100] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   101] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   102] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   103] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   104] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   105] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   106] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   107] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   108] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   109] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   110] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   111] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   112] loss: 0.053, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   113] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   114] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   115] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   116] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   117] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   118] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   119] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   120] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   121] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   122] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   123] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   124] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   125] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   126] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   127] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   128] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   129] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   130] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   131] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   132] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   133] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   134] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   135] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   136] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   137] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   138] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   139] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   140] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   141] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   142] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   143] loss: 0.087, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   144] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   145] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   146] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   147] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   148] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   149] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   150] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   151] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   152] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   153] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   154] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   155] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   156] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   157] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   158] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   159] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   160] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   161] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   162] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   163] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   164] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   165] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   166] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   167] loss: 0.066, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   168] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   169] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   170] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   171] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   172] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   173] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   174] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   175] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   176] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   177] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   178] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   179] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   180] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   181] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   182] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   183] loss: 0.071, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   184] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   185] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   186] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   187] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   188] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   189] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   190] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   191] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   192] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   193] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   194] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   195] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   196] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   197] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   198] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   199] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   200] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   201] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   202] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   203] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   204] loss: 0.073, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   205] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   206] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   207] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   208] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   209] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   210] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   211] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   212] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   213] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   214] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   215] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   216] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   217] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   218] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   219] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   220] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   221] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   222] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   223] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   224] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   225] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   226] loss: 0.071, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   227] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   228] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   229] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   230] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   231] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   232] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   233] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   234] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   235] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   236] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   237] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   238] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   239] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   240] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   241] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   242] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   243] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   244] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   245] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   246] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   247] loss: 0.115, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   248] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   249] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   250] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   251] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   252] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   253] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   254] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   255] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   256] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   257] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   258] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   259] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   260] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   261] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   262] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   263] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   264] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   265] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   266] loss: 0.074, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   267] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   268] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   269] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   270] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   271] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   272] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   273] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   274] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   275] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   276] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   277] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   278] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   279] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   280] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   281] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   282] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   283] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   284] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   285] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   286] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   287] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   288] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   289] loss: 0.080, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   290] loss: 0.079, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   291] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   292] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   293] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   294] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   295] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   296] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   297] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   298] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   299] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   300] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   301] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   302] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   303] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   304] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   305] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   306] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   307] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   308] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   309] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   310] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   311] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   312] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   313] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   314] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   315] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   316] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   317] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   318] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   319] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   320] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   321] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   322] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   323] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   324] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   325] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   326] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   327] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   328] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   329] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   330] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   331] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   332] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   333] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   334] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   335] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   336] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   337] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   338] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   339] loss: 0.068, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   340] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   341] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   342] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   343] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   344] loss: 0.079, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   345] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   346] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   347] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   348] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   349] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   350] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   351] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   352] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   353] loss: 0.075, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   354] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   355] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   356] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   357] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   358] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   359] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   360] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   361] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   362] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   363] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   364] loss: 0.114, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   365] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   366] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   367] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   368] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   369] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   370] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   371] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   372] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   373] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   374] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   375] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   376] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   377] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   378] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   379] loss: 0.112, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   380] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   381] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   382] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   383] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   384] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   385] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   386] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   387] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   388] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   389] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   390] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   391] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   392] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   393] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   394] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   395] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   396] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   397] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   398] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   399] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   400] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   401] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   402] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   403] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    19/   30, batch:   404] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.026, val loss 0.213, val accuracy 0.951, and val rmse 0.286\n",
            "[epoch:    20/   30, batch:     1] loss: 0.051, lr: 0.0010000000, acc 97 %\n",
            "[epoch:    20/   30, batch:     2] loss: 0.057, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:     3] loss: 0.044, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:     4] loss: 0.083, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:     5] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:     6] loss: 0.025, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:     7] loss: 0.010, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:     8] loss: 0.021, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:     9] loss: 0.023, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    10] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    11] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    12] loss: 0.052, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    13] loss: 0.024, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    14] loss: 0.027, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    15] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    16] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    17] loss: 0.002, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    18] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    19] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    20] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    21] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    22] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    23] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    24] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    25] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    26] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    27] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    28] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    29] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    20/   30, batch:    30] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    31] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    32] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    33] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    34] loss: 0.064, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    35] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    36] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    37] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    38] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    39] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    40] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    41] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    42] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    43] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    44] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    45] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    46] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    47] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    48] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    49] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    50] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    51] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    52] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    53] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    54] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    55] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    56] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    57] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    58] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    59] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    60] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    61] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    62] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    63] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    64] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    65] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    66] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    67] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    68] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    69] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    70] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    71] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    72] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    73] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    74] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    75] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    76] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    77] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    78] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    79] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    80] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    81] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    82] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    83] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    84] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    85] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    86] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    87] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    88] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    89] loss: 0.066, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    90] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    91] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    92] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    93] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    94] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    95] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    96] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    97] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    98] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:    99] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   100] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   101] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   102] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   103] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   104] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   105] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   106] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   107] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   108] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   109] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   110] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   111] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   112] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   113] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   114] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   115] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   116] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   117] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   118] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   119] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   120] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   121] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   122] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   123] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   124] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   125] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   126] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   127] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   128] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   129] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   130] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   131] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   132] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   133] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   134] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   135] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   136] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   137] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   138] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   139] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   140] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   141] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   142] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   143] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   144] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   145] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   146] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   147] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   148] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   149] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   150] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   151] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   152] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   153] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   154] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   155] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   156] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   157] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   158] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   159] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   160] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   161] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   162] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   163] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   164] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   165] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   166] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   167] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   168] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   169] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   170] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   171] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   172] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   173] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   174] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   175] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   176] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   177] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   178] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   179] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   180] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   181] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   182] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   183] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   184] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   185] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   186] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   187] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   188] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   189] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   190] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   191] loss: 0.067, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   192] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   193] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   194] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   195] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   196] loss: 0.068, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   197] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   198] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   199] loss: 0.083, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   200] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   201] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   202] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   203] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   204] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   205] loss: 0.065, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   206] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   207] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   208] loss: 0.064, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   209] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   210] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   211] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   212] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   213] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   214] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   215] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   216] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   217] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   218] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   219] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   220] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   221] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   222] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   223] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   224] loss: 0.094, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   225] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   226] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   227] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   228] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   229] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   230] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   231] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   232] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   233] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   234] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   235] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   236] loss: 0.065, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   237] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   238] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   239] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   240] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   241] loss: 0.098, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   242] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   243] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   244] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   245] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   246] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   247] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   248] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   249] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   250] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   251] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   252] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   253] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   254] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   255] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   256] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   257] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   258] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   259] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   260] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   261] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   262] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   263] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   264] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   265] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   266] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   267] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   268] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   269] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   270] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   271] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   272] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   273] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   274] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   275] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   276] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   277] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   278] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   279] loss: 0.070, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   280] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   281] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   282] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   283] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   284] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   285] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   286] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   287] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   288] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   289] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   290] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   291] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   292] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   293] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   294] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   295] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   296] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   297] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   298] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   299] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   300] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   301] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   302] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   303] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   304] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   305] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   306] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   307] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   308] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   309] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   310] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   311] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   312] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   313] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   314] loss: 0.070, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   315] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   316] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   317] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   318] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   319] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   320] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   321] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   322] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   323] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   324] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   325] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   326] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   327] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   328] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   329] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   330] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   331] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   332] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   333] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   334] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   335] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   336] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   337] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   338] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   339] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   340] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   341] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   342] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   343] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   344] loss: 0.067, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   345] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   346] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   347] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   348] loss: 0.069, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   349] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   350] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   351] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   352] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   353] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   354] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   355] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   356] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   357] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   358] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   359] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   360] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   361] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   362] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   363] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   364] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   365] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   366] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   367] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   368] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   369] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   370] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   371] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   372] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   373] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   374] loss: 0.065, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   375] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   376] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   377] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   378] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   379] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   380] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   381] loss: 0.136, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   382] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   383] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   384] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   385] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   386] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   387] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   388] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   389] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   390] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   391] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   392] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   393] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   394] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   395] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   396] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   397] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   398] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   399] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   400] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   401] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   402] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   403] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    20/   30, batch:   404] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.025, val loss 0.209, val accuracy 0.952, and val rmse 0.285\n",
            "[epoch:    21/   30, batch:     1] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:     2] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:     3] loss: 0.033, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:     4] loss: 0.093, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:     5] loss: 0.035, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:     6] loss: 0.030, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:     7] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:     8] loss: 0.020, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:     9] loss: 0.056, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    10] loss: 0.036, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    11] loss: 0.056, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    12] loss: 0.018, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    13] loss: 0.007, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    14] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    15] loss: 0.011, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    16] loss: 0.035, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    17] loss: 0.034, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    18] loss: 0.022, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    19] loss: 0.004, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    20] loss: 0.049, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    21] loss: 0.028, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    22] loss: 0.042, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    23] loss: 0.008, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    24] loss: 0.014, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    25] loss: 0.055, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    26] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    27] loss: 0.003, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    21/   30, batch:    28] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    29] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    30] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    31] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    32] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    33] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    34] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    35] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    36] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    37] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    38] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    39] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    40] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    41] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    42] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    43] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    44] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    45] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    46] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    47] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    48] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    49] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    50] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    51] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    52] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    53] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    54] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    55] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    56] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    57] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    58] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    59] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    60] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    61] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    62] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    63] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    64] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    65] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    66] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    67] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    68] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    69] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    70] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    71] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    72] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    73] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    74] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    75] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    76] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    77] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    78] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    79] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    80] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    81] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    82] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    83] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    84] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    85] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    86] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    87] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    88] loss: 0.081, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    89] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    90] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    91] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    92] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    93] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    94] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    95] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    96] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    97] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    98] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:    99] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   100] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   101] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   102] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   103] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   104] loss: 0.068, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   105] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   106] loss: 0.070, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   107] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   108] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   109] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   110] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   111] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   112] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   113] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   114] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   115] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   116] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   117] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   118] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   119] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   120] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   121] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   122] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   123] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   124] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   125] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   126] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   127] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   128] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   129] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   130] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   131] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   132] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   133] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   134] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   135] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   136] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   137] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   138] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   139] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   140] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   141] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   142] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   143] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   144] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   145] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   146] loss: 0.081, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   147] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   148] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   149] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   150] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   151] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   152] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   153] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   154] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   155] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   156] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   157] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   158] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   159] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   160] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   161] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   162] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   163] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   164] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   165] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   166] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   167] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   168] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   169] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   170] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   171] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   172] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   173] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   174] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   175] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   176] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   177] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   178] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   179] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   180] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   181] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   182] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   183] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   184] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   185] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   186] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   187] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   188] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   189] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   190] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   191] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   192] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   193] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   194] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   195] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   196] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   197] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   198] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   199] loss: 0.070, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   200] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   201] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   202] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   203] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   204] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   205] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   206] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   207] loss: 0.080, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   208] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   209] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   210] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   211] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   212] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   213] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   214] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   215] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   216] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   217] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   218] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   219] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   220] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   221] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   222] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   223] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   224] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   225] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   226] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   227] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   228] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   229] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   230] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   231] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   232] loss: 0.072, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   233] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   234] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   235] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   236] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   237] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   238] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   239] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   240] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   241] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   242] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   243] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   244] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   245] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   246] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   247] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   248] loss: 0.065, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   249] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   250] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   251] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   252] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   253] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   254] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   255] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   256] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   257] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   258] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   259] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   260] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   261] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   262] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   263] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   264] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   265] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   266] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   267] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   268] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   269] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   270] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   271] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   272] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   273] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   274] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   275] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   276] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   277] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   278] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   279] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   280] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   281] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   282] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   283] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   284] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   285] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   286] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   287] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   288] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   289] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   290] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   291] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   292] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   293] loss: 0.081, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   294] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   295] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   296] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   297] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   298] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   299] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   300] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   301] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   302] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   303] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   304] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   305] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   306] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   307] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   308] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   309] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   310] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   311] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   312] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   313] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   314] loss: 0.060, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   315] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   316] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   317] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   318] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   319] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   320] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   321] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   322] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   323] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   324] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   325] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   326] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   327] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   328] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   329] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   330] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   331] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   332] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   333] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   334] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   335] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   336] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   337] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   338] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   339] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   340] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   341] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   342] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   343] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   344] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   345] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   346] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   347] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   348] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   349] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   350] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   351] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   352] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   353] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   354] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   355] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   356] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   357] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   358] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   359] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   360] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   361] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   362] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   363] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   364] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   365] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   366] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   367] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   368] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   369] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   370] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   371] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   372] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   373] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   374] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   375] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   376] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   377] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   378] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   379] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   380] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   381] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   382] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   383] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   384] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   385] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   386] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   387] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   388] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   389] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   390] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   391] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   392] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   393] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   394] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   395] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   396] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   397] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   398] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   399] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   400] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   401] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   402] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   403] loss: 0.091, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    21/   30, batch:   404] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.023, val loss 0.218, val accuracy 0.952, and val rmse 0.282\n",
            "[epoch:    22/   30, batch:     1] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:     2] loss: 0.031, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    22/   30, batch:     3] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    22/   30, batch:     4] loss: 0.037, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    22/   30, batch:     5] loss: 0.019, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    22/   30, batch:     6] loss: 0.015, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    22/   30, batch:     7] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:     8] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:     9] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    10] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    11] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    12] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    13] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    14] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    15] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    16] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    17] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    18] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    19] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    20] loss: 0.090, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    21] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    22] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    23] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    24] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    25] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    26] loss: 0.077, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    27] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    28] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    29] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    30] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    31] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    32] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    33] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    34] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    35] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    36] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    37] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    38] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    39] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    40] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    41] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    42] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    43] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    44] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    45] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    46] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    47] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    48] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    49] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    50] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    51] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    52] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    53] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    54] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    55] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    56] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    57] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    58] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    59] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    60] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    61] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    62] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    63] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    64] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    65] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    66] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    67] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    68] loss: 0.107, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    69] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    70] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    71] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    72] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    73] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    74] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    75] loss: 0.068, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    76] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    77] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    78] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    79] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    80] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    81] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    82] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    83] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    84] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    85] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    86] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    87] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    88] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    89] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    90] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    91] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    92] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    93] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    94] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    95] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    96] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    97] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    98] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:    99] loss: 0.072, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   100] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   101] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   102] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   103] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   104] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   105] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   106] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   107] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   108] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   109] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   110] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   111] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   112] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   113] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   114] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   115] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   116] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   117] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   118] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   119] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   120] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   121] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   122] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   123] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   124] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   125] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   126] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   127] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   128] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   129] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   130] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   131] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   132] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   133] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   134] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   135] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   136] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   137] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   138] loss: 0.087, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   139] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   140] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   141] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   142] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   143] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   144] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   145] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   146] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   147] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   148] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   149] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   150] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   151] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   152] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   153] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   154] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   155] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   156] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   157] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   158] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   159] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   160] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   161] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   162] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   163] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   164] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   165] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   166] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   167] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   168] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   169] loss: 0.079, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   170] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   171] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   172] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   173] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   174] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   175] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   176] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   177] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   178] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   179] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   180] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   181] loss: 0.069, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   182] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   183] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   184] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   185] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   186] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   187] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   188] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   189] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   190] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   191] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   192] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   193] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   194] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   195] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   196] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   197] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   198] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   199] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   200] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   201] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   202] loss: 0.064, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   203] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   204] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   205] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   206] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   207] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   208] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   209] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   210] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   211] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   212] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   213] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   214] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   215] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   216] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   217] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   218] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   219] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   220] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   221] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   222] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   223] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   224] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   225] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   226] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   227] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   228] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   229] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   230] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   231] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   232] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   233] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   234] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   235] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   236] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   237] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   238] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   239] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   240] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   241] loss: 0.073, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   242] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   243] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   244] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   245] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   246] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   247] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   248] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   249] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   250] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   251] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   252] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   253] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   254] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   255] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   256] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   257] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   258] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   259] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   260] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   261] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   262] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   263] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   264] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   265] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   266] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   267] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   268] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   269] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   270] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   271] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   272] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   273] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   274] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   275] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   276] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   277] loss: 0.060, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   278] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   279] loss: 0.060, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   280] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   281] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   282] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   283] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   284] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   285] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   286] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   287] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   288] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   289] loss: 0.099, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   290] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   291] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   292] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   293] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   294] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   295] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   296] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   297] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   298] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   299] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   300] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   301] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   302] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   303] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   304] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   305] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   306] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   307] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   308] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   309] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   310] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   311] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   312] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   313] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   314] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   315] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   316] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   317] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   318] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   319] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   320] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   321] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   322] loss: 0.082, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   323] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   324] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   325] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   326] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   327] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   328] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   329] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   330] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   331] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   332] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   333] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   334] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   335] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   336] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   337] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   338] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   339] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   340] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   341] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   342] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   343] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   344] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   345] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   346] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   347] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   348] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   349] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   350] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   351] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   352] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   353] loss: 0.068, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   354] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   355] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   356] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   357] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   358] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   359] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   360] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   361] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   362] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   363] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   364] loss: 0.069, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   365] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   366] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   367] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   368] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   369] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   370] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   371] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   372] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   373] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   374] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   375] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   376] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   377] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   378] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   379] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   380] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   381] loss: 0.086, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   382] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   383] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   384] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   385] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   386] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   387] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   388] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   389] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   390] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   391] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   392] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   393] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   394] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   395] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   396] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   397] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   398] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   399] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   400] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   401] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   402] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   403] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    22/   30, batch:   404] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.021, val loss 0.225, val accuracy 0.951, and val rmse 0.284\n",
            "[epoch:    23/   30, batch:     1] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:     2] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:     3] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:     4] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:     5] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:     6] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:     7] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:     8] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:     9] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    10] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    11] loss: 0.064, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    12] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    13] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    14] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    15] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    16] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    17] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    18] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    19] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    20] loss: 0.071, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    21] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    22] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    23] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    24] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    25] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    26] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    27] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    28] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    29] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    30] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    31] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    32] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    33] loss: 0.060, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    34] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    35] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    36] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    37] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    38] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    39] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    40] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    41] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    42] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    43] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    44] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    45] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    46] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    47] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    48] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    49] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    50] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    51] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    52] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    53] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    54] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    55] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    56] loss: 0.072, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    57] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    58] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    59] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    60] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    61] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    62] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    63] loss: 0.072, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    64] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    65] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    66] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    67] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    68] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    69] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    70] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    71] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    72] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    73] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    74] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    75] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    76] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    77] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    78] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    79] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    80] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    81] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    82] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    83] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    84] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    85] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    86] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    87] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    88] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    89] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    90] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    91] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    92] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    93] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    94] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    95] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    96] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    97] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    98] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:    99] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   100] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   101] loss: 0.069, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   102] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   103] loss: 0.071, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   104] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   105] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   106] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   107] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   108] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   109] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   110] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   111] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   112] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   113] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   114] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   115] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   116] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   117] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   118] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   119] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   120] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   121] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   122] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   123] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   124] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   125] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   126] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   127] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   128] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   129] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   130] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   131] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   132] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   133] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   134] loss: 0.064, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   135] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   136] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   137] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   138] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   139] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   140] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   141] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   142] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   143] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   144] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   145] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   146] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   147] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   148] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   149] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   150] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   151] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   152] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   153] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   154] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   155] loss: 0.108, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   156] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   157] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   158] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   159] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   160] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   161] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   162] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   163] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   164] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   165] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   166] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   167] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   168] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   169] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   170] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   171] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   172] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   173] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   174] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   175] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   176] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   177] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   178] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   179] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   180] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   181] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   182] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   183] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   184] loss: 0.053, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   185] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   186] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   187] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   188] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   189] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   190] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   191] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   192] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   193] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   194] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   195] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   196] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   197] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   198] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   199] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   200] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   201] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   202] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   203] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   204] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   205] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   206] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   207] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   208] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   209] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   210] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   211] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   212] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   213] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   214] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   215] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   216] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   217] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   218] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   219] loss: 0.065, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   220] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   221] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   222] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   223] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   224] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   225] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   226] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   227] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   228] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   229] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   230] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   231] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   232] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   233] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   234] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   235] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   236] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   237] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   238] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   239] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   240] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   241] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   242] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   243] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   244] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   245] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   246] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   247] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   248] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   249] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   250] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   251] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   252] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   253] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   254] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   255] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   256] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   257] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   258] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   259] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   260] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   261] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   262] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   263] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   264] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   265] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   266] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   267] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   268] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   269] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   270] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   271] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   272] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   273] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   274] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   275] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   276] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   277] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   278] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   279] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   280] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   281] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   282] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   283] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   284] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   285] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   286] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   287] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   288] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   289] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   290] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   291] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   292] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   293] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   294] loss: 0.065, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   295] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   296] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   297] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   298] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   299] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   300] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   301] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   302] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   303] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   304] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   305] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   306] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   307] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   308] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   309] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   310] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   311] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   312] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   313] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   314] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   315] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   316] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   317] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   318] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   319] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   320] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   321] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   322] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   323] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   324] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   325] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   326] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   327] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   328] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   329] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   330] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   331] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   332] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   333] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   334] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   335] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   336] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   337] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   338] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   339] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   340] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   341] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   342] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   343] loss: 0.071, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   344] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   345] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   346] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   347] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   348] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   349] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   350] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   351] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   352] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   353] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   354] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   355] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   356] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   357] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   358] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   359] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   360] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   361] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   362] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   363] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   364] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   365] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   366] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   367] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   368] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   369] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   370] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   371] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   372] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   373] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   374] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   375] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   376] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   377] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   378] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   379] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   380] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   381] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   382] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   383] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   384] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   385] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   386] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   387] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   388] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   389] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   390] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   391] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   392] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   393] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   394] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   395] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   396] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   397] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   398] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   399] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   400] loss: 0.064, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   401] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   402] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   403] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    23/   30, batch:   404] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.019, val loss 0.237, val accuracy 0.951, and val rmse 0.290\n",
            "[epoch:    24/   30, batch:     1] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:     2] loss: 0.043, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    24/   30, batch:     3] loss: 0.004, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    24/   30, batch:     4] loss: 0.045, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    24/   30, batch:     5] loss: 0.005, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    24/   30, batch:     6] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:     7] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:     8] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:     9] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    10] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    11] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    12] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    13] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    14] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    15] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    16] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    17] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    18] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    19] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    20] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    21] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    22] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    23] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    24] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    25] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    26] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    27] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    28] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    29] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    30] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    31] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    32] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    33] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    34] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    35] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    36] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    37] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    38] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    39] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    40] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    41] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    42] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    43] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    44] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    45] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    46] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    47] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    48] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    49] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    50] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    51] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    52] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    53] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    54] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    55] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    56] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    57] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    58] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    59] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    60] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    61] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    62] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    63] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    64] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    65] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    66] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    67] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    68] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    69] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    70] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    71] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    72] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    73] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    74] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    75] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    76] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    77] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    78] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    79] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    80] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    81] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    82] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    83] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    84] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    85] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    86] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    87] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    88] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    89] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    90] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    91] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    92] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    93] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    94] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    95] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    96] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    97] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    98] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:    99] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   100] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   101] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   102] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   103] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   104] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   105] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   106] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   107] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   108] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   109] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   110] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   111] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   112] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   113] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   114] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   115] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   116] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   117] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   118] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   119] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   120] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   121] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   122] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   123] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   124] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   125] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   126] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   127] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   128] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   129] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   130] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   131] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   132] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   133] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   134] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   135] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   136] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   137] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   138] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   139] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   140] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   141] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   142] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   143] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   144] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   145] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   146] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   147] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   148] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   149] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   150] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   151] loss: 0.067, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   152] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   153] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   154] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   155] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   156] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   157] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   158] loss: 0.080, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   159] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   160] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   161] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   162] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   163] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   164] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   165] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   166] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   167] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   168] loss: 0.066, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   169] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   170] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   171] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   172] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   173] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   174] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   175] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   176] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   177] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   178] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   179] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   180] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   181] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   182] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   183] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   184] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   185] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   186] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   187] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   188] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   189] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   190] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   191] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   192] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   193] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   194] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   195] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   196] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   197] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   198] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   199] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   200] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   201] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   202] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   203] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   204] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   205] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   206] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   207] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   208] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   209] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   210] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   211] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   212] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   213] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   214] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   215] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   216] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   217] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   218] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   219] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   220] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   221] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   222] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   223] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   224] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   225] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   226] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   227] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   228] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   229] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   230] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   231] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   232] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   233] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   234] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   235] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   236] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   237] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   238] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   239] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   240] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   241] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   242] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   243] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   244] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   245] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   246] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   247] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   248] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   249] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   250] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   251] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   252] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   253] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   254] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   255] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   256] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   257] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   258] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   259] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   260] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   261] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   262] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   263] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   264] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   265] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   266] loss: 0.076, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   267] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   268] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   269] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   270] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   271] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   272] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   273] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   274] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   275] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   276] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   277] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   278] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   279] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   280] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   281] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   282] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   283] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   284] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   285] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   286] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   287] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   288] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   289] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   290] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   291] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   292] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   293] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   294] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   295] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   296] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   297] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   298] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   299] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   300] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   301] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   302] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   303] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   304] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   305] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   306] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   307] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   308] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   309] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   310] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   311] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   312] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   313] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   314] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   315] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   316] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   317] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   318] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   319] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   320] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   321] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   322] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   323] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   324] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   325] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   326] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   327] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   328] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   329] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   330] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   331] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   332] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   333] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   334] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   335] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   336] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   337] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   338] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   339] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   340] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   341] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   342] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   343] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   344] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   345] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   346] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   347] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   348] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   349] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   350] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   351] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   352] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   353] loss: 0.081, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   354] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   355] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   356] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   357] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   358] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   359] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   360] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   361] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   362] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   363] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   364] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   365] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   366] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   367] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   368] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   369] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   370] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   371] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   372] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   373] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   374] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   375] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   376] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   377] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   378] loss: 0.068, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   379] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   380] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   381] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   382] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   383] loss: 0.066, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   384] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   385] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   386] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   387] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   388] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   389] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   390] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   391] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   392] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   393] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   394] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   395] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   396] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   397] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   398] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   399] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   400] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   401] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   402] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   403] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    24/   30, batch:   404] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.019, val loss 0.223, val accuracy 0.951, and val rmse 0.292\n",
            "[epoch:    25/   30, batch:     1] loss: 0.004, lr: 0.0010000000, acc 100 %\n",
            "[epoch:    25/   30, batch:     2] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:     3] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:     4] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:     5] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:     6] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:     7] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:     8] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:     9] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    10] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    11] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    12] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    13] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    14] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    15] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    16] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    17] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    18] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    19] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    20] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    21] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    22] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    23] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    24] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    25] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    26] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    27] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    28] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    29] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    30] loss: 0.053, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    31] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    32] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    33] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    34] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    35] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    36] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    37] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    38] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    39] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    40] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    41] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    42] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    43] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    44] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    45] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    46] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    47] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    48] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    49] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    50] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    51] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    52] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    53] loss: 0.000, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    54] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    55] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    56] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    57] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    58] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    59] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    60] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    61] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    62] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    63] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    64] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    65] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    66] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    67] loss: 0.081, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    68] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    69] loss: 0.053, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    70] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    71] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    72] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    73] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    74] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    75] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    76] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    77] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    78] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    79] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    80] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    81] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    82] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    83] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    84] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    85] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    86] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    87] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    88] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    89] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    90] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    91] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    92] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    93] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    94] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    95] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    96] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    97] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    98] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:    99] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   100] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   101] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   102] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   103] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   104] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   105] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   106] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   107] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   108] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   109] loss: 0.070, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   110] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   111] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   112] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   113] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   114] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   115] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   116] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   117] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   118] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   119] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   120] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   121] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   122] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   123] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   124] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   125] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   126] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   127] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   128] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   129] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   130] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   131] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   132] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   133] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   134] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   135] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   136] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   137] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   138] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   139] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   140] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   141] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   142] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   143] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   144] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   145] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   146] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   147] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   148] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   149] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   150] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   151] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   152] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   153] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   154] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   155] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   156] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   157] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   158] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   159] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   160] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   161] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   162] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   163] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   164] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   165] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   166] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   167] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   168] loss: 0.068, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   169] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   170] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   171] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   172] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   173] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   174] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   175] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   176] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   177] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   178] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   179] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   180] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   181] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   182] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   183] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   184] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   185] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   186] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   187] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   188] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   189] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   190] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   191] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   192] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   193] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   194] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   195] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   196] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   197] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   198] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   199] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   200] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   201] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   202] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   203] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   204] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   205] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   206] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   207] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   208] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   209] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   210] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   211] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   212] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   213] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   214] loss: 0.067, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   215] loss: 0.091, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   216] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   217] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   218] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   219] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   220] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   221] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   222] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   223] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   224] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   225] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   226] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   227] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   228] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   229] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   230] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   231] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   232] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   233] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   234] loss: 0.065, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   235] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   236] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   237] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   238] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   239] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   240] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   241] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   242] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   243] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   244] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   245] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   246] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   247] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   248] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   249] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   250] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   251] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   252] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   253] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   254] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   255] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   256] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   257] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   258] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   259] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   260] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   261] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   262] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   263] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   264] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   265] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   266] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   267] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   268] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   269] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   270] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   271] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   272] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   273] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   274] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   275] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   276] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   277] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   278] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   279] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   280] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   281] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   282] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   283] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   284] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   285] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   286] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   287] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   288] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   289] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   290] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   291] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   292] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   293] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   294] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   295] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   296] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   297] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   298] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   299] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   300] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   301] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   302] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   303] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   304] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   305] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   306] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   307] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   308] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   309] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   310] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   311] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   312] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   313] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   314] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   315] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   316] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   317] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   318] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   319] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   320] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   321] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   322] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   323] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   324] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   325] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   326] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   327] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   328] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   329] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   330] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   331] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   332] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   333] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   334] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   335] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   336] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   337] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   338] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   339] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   340] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   341] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   342] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   343] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   344] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   345] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   346] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   347] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   348] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   349] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   350] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   351] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   352] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   353] loss: 0.111, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   354] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   355] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   356] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   357] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   358] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   359] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   360] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   361] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   362] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   363] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   364] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   365] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   366] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   367] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   368] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   369] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   370] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   371] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   372] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   373] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   374] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   375] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   376] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   377] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   378] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   379] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   380] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   381] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   382] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   383] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   384] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   385] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   386] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   387] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   388] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   389] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   390] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   391] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   392] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   393] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   394] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   395] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   396] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   397] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   398] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   399] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   400] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   401] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   402] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   403] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    25/   30, batch:   404] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.017, val loss 0.244, val accuracy 0.952, and val rmse 0.289\n",
            "[epoch:    26/   30, batch:     1] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:     2] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:     3] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:     4] loss: 0.104, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:     5] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:     6] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:     7] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:     8] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:     9] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    10] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    11] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    12] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    13] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    14] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    15] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    16] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    17] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    18] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    19] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    20] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    21] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    22] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    23] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    24] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    25] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    26] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    27] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    28] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    29] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    30] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    31] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    32] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    33] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    34] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    35] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    36] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    37] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    38] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    39] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    40] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    41] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    42] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    43] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    44] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    45] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    46] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    47] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    48] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    49] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    50] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    51] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    52] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    53] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    54] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    55] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    56] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    57] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    58] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    59] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    60] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    61] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    62] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    63] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    64] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    65] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    66] loss: 0.103, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    67] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    68] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    69] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    70] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    71] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    72] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    73] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    74] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    75] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    76] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    77] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    78] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    79] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    80] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    81] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    82] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    83] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    84] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    85] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    86] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    87] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    88] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    89] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    90] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    91] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    92] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    93] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    94] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    95] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    96] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    97] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    98] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:    99] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   100] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   101] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   102] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   103] loss: 0.065, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   104] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   105] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   106] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   107] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   108] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   109] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   110] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   111] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   112] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   113] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   114] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   115] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   116] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   117] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   118] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   119] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   120] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   121] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   122] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   123] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   124] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   125] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   126] loss: 0.077, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   127] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   128] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   129] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   130] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   131] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   132] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   133] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   134] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   135] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   136] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   137] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   138] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   139] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   140] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   141] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   142] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   143] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   144] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   145] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   146] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   147] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   148] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   149] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   150] loss: 0.069, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   151] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   152] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   153] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   154] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   155] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   156] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   157] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   158] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   159] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   160] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   161] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   162] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   163] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   164] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   165] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   166] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   167] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   168] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   169] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   170] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   171] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   172] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   173] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   174] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   175] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   176] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   177] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   178] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   179] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   180] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   181] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   182] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   183] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   184] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   185] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   186] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   187] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   188] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   189] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   190] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   191] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   192] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   193] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   194] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   195] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   196] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   197] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   198] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   199] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   200] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   201] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   202] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   203] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   204] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   205] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   206] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   207] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   208] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   209] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   210] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   211] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   212] loss: 0.054, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   213] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   214] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   215] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   216] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   217] loss: 0.091, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   218] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   219] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   220] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   221] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   222] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   223] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   224] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   225] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   226] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   227] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   228] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   229] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   230] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   231] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   232] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   233] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   234] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   235] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   236] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   237] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   238] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   239] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   240] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   241] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   242] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   243] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   244] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   245] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   246] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   247] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   248] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   249] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   250] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   251] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   252] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   253] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   254] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   255] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   256] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   257] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   258] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   259] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   260] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   261] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   262] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   263] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   264] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   265] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   266] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   267] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   268] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   269] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   270] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   271] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   272] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   273] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   274] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   275] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   276] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   277] loss: 0.103, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   278] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   279] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   280] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   281] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   282] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   283] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   284] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   285] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   286] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   287] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   288] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   289] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   290] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   291] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   292] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   293] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   294] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   295] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   296] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   297] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   298] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   299] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   300] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   301] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   302] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   303] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   304] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   305] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   306] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   307] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   308] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   309] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   310] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   311] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   312] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   313] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   314] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   315] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   316] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   317] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   318] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   319] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   320] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   321] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   322] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   323] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   324] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   325] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   326] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   327] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   328] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   329] loss: 0.057, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   330] loss: 0.000, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   331] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   332] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   333] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   334] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   335] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   336] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   337] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   338] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   339] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   340] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   341] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   342] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   343] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   344] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   345] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   346] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   347] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   348] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   349] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   350] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   351] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   352] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   353] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   354] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   355] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   356] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   357] loss: 0.000, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   358] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   359] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   360] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   361] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   362] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   363] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   364] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   365] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   366] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   367] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   368] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   369] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   370] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   371] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   372] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   373] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   374] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   375] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   376] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   377] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   378] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   379] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   380] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   381] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   382] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   383] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   384] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   385] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   386] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   387] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   388] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   389] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   390] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   391] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   392] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   393] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   394] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   395] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   396] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   397] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   398] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   399] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   400] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   401] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   402] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   403] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    26/   30, batch:   404] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.015, val loss 0.242, val accuracy 0.953, and val rmse 0.278\n",
            "[epoch:    27/   30, batch:     1] loss: 0.029, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    27/   30, batch:     2] loss: 0.041, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    27/   30, batch:     3] loss: 0.017, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    27/   30, batch:     4] loss: 0.044, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    27/   30, batch:     5] loss: 0.012, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    27/   30, batch:     6] loss: 0.002, lr: 0.0010000000, acc 98 %\n",
            "[epoch:    27/   30, batch:     7] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:     8] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:     9] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    10] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    11] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    12] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    13] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    14] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    15] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    16] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    17] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    18] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    19] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    20] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    21] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    22] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    23] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    24] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    25] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    26] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    27] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    28] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    29] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    30] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    31] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    32] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    33] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    34] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    35] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    36] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    37] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    38] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    39] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    40] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    41] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    42] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    43] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    44] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    45] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    46] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    47] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    48] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    49] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    50] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    51] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    52] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    53] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    54] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    55] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    56] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    57] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    58] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    59] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    60] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    61] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    62] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    63] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    64] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    65] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    66] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    67] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    68] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    69] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    70] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    71] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    72] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    73] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    74] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    75] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    76] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    77] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    78] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    79] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    80] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    81] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    82] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    83] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    84] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    85] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    86] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    87] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    88] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    89] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    90] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    91] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    92] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    93] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    94] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    95] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    96] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    97] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    98] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:    99] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   100] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   101] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   102] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   103] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   104] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   105] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   106] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   107] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   108] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   109] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   110] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   111] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   112] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   113] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   114] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   115] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   116] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   117] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   118] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   119] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   120] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   121] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   122] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   123] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   124] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   125] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   126] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   127] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   128] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   129] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   130] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   131] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   132] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   133] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   134] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   135] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   136] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   137] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   138] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   139] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   140] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   141] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   142] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   143] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   144] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   145] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   146] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   147] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   148] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   149] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   150] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   151] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   152] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   153] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   154] loss: 0.060, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   155] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   156] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   157] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   158] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   159] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   160] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   161] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   162] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   163] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   164] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   165] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   166] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   167] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   168] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   169] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   170] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   171] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   172] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   173] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   174] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   175] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   176] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   177] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   178] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   179] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   180] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   181] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   182] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   183] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   184] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   185] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   186] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   187] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   188] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   189] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   190] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   191] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   192] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   193] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   194] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   195] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   196] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   197] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   198] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   199] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   200] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   201] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   202] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   203] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   204] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   205] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   206] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   207] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   208] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   209] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   210] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   211] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   212] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   213] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   214] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   215] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   216] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   217] loss: 0.072, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   218] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   219] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   220] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   221] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   222] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   223] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   224] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   225] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   226] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   227] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   228] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   229] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   230] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   231] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   232] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   233] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   234] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   235] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   236] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   237] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   238] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   239] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   240] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   241] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   242] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   243] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   244] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   245] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   246] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   247] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   248] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   249] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   250] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   251] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   252] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   253] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   254] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   255] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   256] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   257] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   258] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   259] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   260] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   261] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   262] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   263] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   264] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   265] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   266] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   267] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   268] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   269] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   270] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   271] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   272] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   273] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   274] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   275] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   276] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   277] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   278] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   279] loss: 0.046, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   280] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   281] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   282] loss: 0.096, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   283] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   284] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   285] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   286] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   287] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   288] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   289] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   290] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   291] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   292] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   293] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   294] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   295] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   296] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   297] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   298] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   299] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   300] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   301] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   302] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   303] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   304] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   305] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   306] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   307] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   308] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   309] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   310] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   311] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   312] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   313] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   314] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   315] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   316] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   317] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   318] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   319] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   320] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   321] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   322] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   323] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   324] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   325] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   326] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   327] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   328] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   329] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   330] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   331] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   332] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   333] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   334] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   335] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   336] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   337] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   338] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   339] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   340] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   341] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   342] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   343] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   344] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   345] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   346] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   347] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   348] loss: 0.066, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   349] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   350] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   351] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   352] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   353] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   354] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   355] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   356] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   357] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   358] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   359] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   360] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   361] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   362] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   363] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   364] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   365] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   366] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   367] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   368] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   369] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   370] loss: 0.056, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   371] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   372] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   373] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   374] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   375] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   376] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   377] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   378] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   379] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   380] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   381] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   382] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   383] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   384] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   385] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   386] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   387] loss: 0.105, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   388] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   389] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   390] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   391] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   392] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   393] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   394] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   395] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   396] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   397] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   398] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   399] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   400] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   401] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   402] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   403] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    27/   30, batch:   404] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.015, val loss 0.249, val accuracy 0.953, and val rmse 0.278\n",
            "[epoch:    28/   30, batch:     1] loss: 0.002, lr: 0.0010000000, acc 100 %\n",
            "[epoch:    28/   30, batch:     2] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:     3] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:     4] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:     5] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:     6] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:     7] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:     8] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:     9] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    10] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    11] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    12] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    13] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    14] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    15] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    16] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    17] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    18] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    19] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    20] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    21] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    22] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    23] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    24] loss: 0.061, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    25] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    26] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    27] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    28] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    29] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    30] loss: 0.080, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    31] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    32] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    33] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    34] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    35] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    36] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    37] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    38] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    39] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    40] loss: 0.071, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    41] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    42] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    43] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    44] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    45] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    46] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    47] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    48] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    49] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    50] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    51] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    52] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    53] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    54] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    55] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    56] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    57] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    58] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    59] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    60] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    61] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    62] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    63] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    64] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    65] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    66] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    67] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    68] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    69] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    70] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    71] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    72] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    73] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    74] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    75] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    76] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    77] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    78] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    79] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    80] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    81] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    82] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    83] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    84] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    85] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    86] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    87] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    88] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    89] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    90] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    91] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    92] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    93] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    94] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    95] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    96] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    97] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    98] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:    99] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   100] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   101] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   102] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   103] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   104] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   105] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   106] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   107] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   108] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   109] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   110] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   111] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   112] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   113] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   114] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   115] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   116] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   117] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   118] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   119] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   120] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   121] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   122] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   123] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   124] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   125] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   126] loss: 0.000, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   127] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   128] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   129] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   130] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   131] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   132] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   133] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   134] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   135] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   136] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   137] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   138] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   139] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   140] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   141] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   142] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   143] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   144] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   145] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   146] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   147] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   148] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   149] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   150] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   151] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   152] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   153] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   154] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   155] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   156] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   157] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   158] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   159] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   160] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   161] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   162] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   163] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   164] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   165] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   166] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   167] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   168] loss: 0.051, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   169] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   170] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   171] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   172] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   173] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   174] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   175] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   176] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   177] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   178] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   179] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   180] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   181] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   182] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   183] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   184] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   185] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   186] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   187] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   188] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   189] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   190] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   191] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   192] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   193] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   194] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   195] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   196] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   197] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   198] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   199] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   200] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   201] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   202] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   203] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   204] loss: 0.074, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   205] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   206] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   207] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   208] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   209] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   210] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   211] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   212] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   213] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   214] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   215] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   216] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   217] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   218] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   219] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   220] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   221] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   222] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   223] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   224] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   225] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   226] loss: 0.091, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   227] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   228] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   229] loss: 0.050, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   230] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   231] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   232] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   233] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   234] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   235] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   236] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   237] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   238] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   239] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   240] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   241] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   242] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   243] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   244] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   245] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   246] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   247] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   248] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   249] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   250] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   251] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   252] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   253] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   254] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   255] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   256] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   257] loss: 0.055, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   258] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   259] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   260] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   261] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   262] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   263] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   264] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   265] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   266] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   267] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   268] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   269] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   270] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   271] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   272] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   273] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   274] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   275] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   276] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   277] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   278] loss: 0.083, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   279] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   280] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   281] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   282] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   283] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   284] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   285] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   286] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   287] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   288] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   289] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   290] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   291] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   292] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   293] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   294] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   295] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   296] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   297] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   298] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   299] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   300] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   301] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   302] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   303] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   304] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   305] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   306] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   307] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   308] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   309] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   310] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   311] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   312] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   313] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   314] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   315] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   316] loss: 0.068, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   317] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   318] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   319] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   320] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   321] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   322] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   323] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   324] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   325] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   326] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   327] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   328] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   329] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   330] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   331] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   332] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   333] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   334] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   335] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   336] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   337] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   338] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   339] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   340] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   341] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   342] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   343] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   344] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   345] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   346] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   347] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   348] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   349] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   350] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   351] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   352] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   353] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   354] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   355] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   356] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   357] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   358] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   359] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   360] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   361] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   362] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   363] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   364] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   365] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   366] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   367] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   368] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   369] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   370] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   371] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   372] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   373] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   374] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   375] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   376] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   377] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   378] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   379] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   380] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   381] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   382] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   383] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   384] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   385] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   386] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   387] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   388] loss: 0.048, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   389] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   390] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   391] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   392] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   393] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   394] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   395] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   396] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   397] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   398] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   399] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   400] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   401] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   402] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   403] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    28/   30, batch:   404] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.015, val loss 0.246, val accuracy 0.952, and val rmse 0.284\n",
            "[epoch:    29/   30, batch:     1] loss: 0.004, lr: 0.0010000000, acc 100 %\n",
            "[epoch:    29/   30, batch:     2] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:     3] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:     4] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:     5] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:     6] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:     7] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:     8] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:     9] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    10] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    11] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    12] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    13] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    14] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    15] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    16] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    17] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    18] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    19] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    20] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    21] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    22] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    23] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    24] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    25] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    26] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    27] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    28] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    29] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    30] loss: 0.040, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    31] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    32] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    33] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    34] loss: 0.066, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    35] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    36] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    37] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    38] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    39] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    40] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    41] loss: 0.125, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    42] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    43] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    44] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    45] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    46] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    47] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    48] loss: 0.028, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    49] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    50] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    51] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    52] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    53] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    54] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    55] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    56] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    57] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    58] loss: 0.036, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    59] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    60] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    61] loss: 0.058, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    62] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    63] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    64] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    65] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    66] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    67] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    68] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    69] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    70] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    71] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    72] loss: 0.053, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    73] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    74] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    75] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    76] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    77] loss: 0.034, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    78] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    79] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    80] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    81] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    82] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    83] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    84] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    85] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    86] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    87] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    88] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    89] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    90] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    91] loss: 0.038, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    92] loss: 0.069, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    93] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    94] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    95] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    96] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    97] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    98] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:    99] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   100] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   101] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   102] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   103] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   104] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   105] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   106] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   107] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   108] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   109] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   110] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   111] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   112] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   113] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   114] loss: 0.060, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   115] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   116] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   117] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   118] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   119] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   120] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   121] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   122] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   123] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   124] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   125] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   126] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   127] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   128] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   129] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   130] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   131] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   132] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   133] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   134] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   135] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   136] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   137] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   138] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   139] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   140] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   141] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   142] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   143] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   144] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   145] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   146] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   147] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   148] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   149] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   150] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   151] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   152] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   153] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   154] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   155] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   156] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   157] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   158] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   159] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   160] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   161] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   162] loss: 0.062, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   163] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   164] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   165] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   166] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   167] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   168] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   169] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   170] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   171] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   172] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   173] loss: 0.039, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   174] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   175] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   176] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   177] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   178] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   179] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   180] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   181] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   182] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   183] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   184] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   185] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   186] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   187] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   188] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   189] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   190] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   191] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   192] loss: 0.037, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   193] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   194] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   195] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   196] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   197] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   198] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   199] loss: 0.044, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   200] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   201] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   202] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   203] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   204] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   205] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   206] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   207] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   208] loss: 0.032, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   209] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   210] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   211] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   212] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   213] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   214] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   215] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   216] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   217] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   218] loss: 0.035, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   219] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   220] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   221] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   222] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   223] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   224] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   225] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   226] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   227] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   228] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   229] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   230] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   231] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   232] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   233] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   234] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   235] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   236] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   237] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   238] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   239] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   240] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   241] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   242] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   243] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   244] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   245] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   246] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   247] loss: 0.045, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   248] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   249] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   250] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   251] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   252] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   253] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   254] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   255] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   256] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   257] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   258] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   259] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   260] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   261] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   262] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   263] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   264] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   265] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   266] loss: 0.024, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   267] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   268] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   269] loss: 0.029, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   270] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   271] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   272] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   273] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   274] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   275] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   276] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   277] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   278] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   279] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   280] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   281] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   282] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   283] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   284] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   285] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   286] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   287] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   288] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   289] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   290] loss: 0.042, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   291] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   292] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   293] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   294] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   295] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   296] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   297] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   298] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   299] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   300] loss: 0.023, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   301] loss: 0.077, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   302] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   303] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   304] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   305] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   306] loss: 0.026, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   307] loss: 0.014, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   308] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   309] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   310] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   311] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   312] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   313] loss: 0.070, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   314] loss: 0.041, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   315] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   316] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   317] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   318] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   319] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   320] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   321] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   322] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   323] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   324] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   325] loss: 0.016, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   326] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   327] loss: 0.018, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   328] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   329] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   330] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   331] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   332] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   333] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   334] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   335] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   336] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   337] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   338] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   339] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   340] loss: 0.013, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   341] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   342] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   343] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   344] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   345] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   346] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   347] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   348] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   349] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   350] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   351] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   352] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   353] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   354] loss: 0.012, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   355] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   356] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   357] loss: 0.022, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   358] loss: 0.031, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   359] loss: 0.021, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   360] loss: 0.011, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   361] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   362] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   363] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   364] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   365] loss: 0.027, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   366] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   367] loss: 0.019, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   368] loss: 0.033, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   369] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   370] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   371] loss: 0.008, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   372] loss: 0.001, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   373] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   374] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   375] loss: 0.063, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   376] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   377] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   378] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   379] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   380] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   381] loss: 0.020, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   382] loss: 0.002, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   383] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   384] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   385] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   386] loss: 0.059, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   387] loss: 0.006, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   388] loss: 0.043, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   389] loss: 0.009, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   390] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   391] loss: 0.017, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   392] loss: 0.030, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   393] loss: 0.052, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   394] loss: 0.000, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   395] loss: 0.005, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   396] loss: 0.049, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   397] loss: 0.047, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   398] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   399] loss: 0.007, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   400] loss: 0.015, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   401] loss: 0.003, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   402] loss: 0.025, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   403] loss: 0.010, lr: 0.0010000000, acc 99 %\n",
            "[epoch:    29/   30, batch:   404] loss: 0.004, lr: 0.0010000000, acc 99 %\n",
            "train loss 0.014, val loss 0.249, val accuracy 0.953, and val rmse 0.280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1lP8QRmq1wQ"
      },
      "source": [
        "## Evaluation using Accuracy & Loss graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HnNYPgoJEU7"
      },
      "source": [
        "def plot_train_val_loss_graph(train_loss_list, val_loss_list, feature_name, stop_words=True, save=True):\n",
        "    x = np.arange(0, NUM_EPOCH)\n",
        "    plt.plot(x, train_loss_list, label=\"train loss\")\n",
        "\n",
        "    plt.plot(x, val_loss_list, label=\"val loss\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"loss %\")\n",
        "    plt.title(f\"Train & Val Loss num {feature_name} Stopwords:{stop_words}\")\n",
        "    plt.legend()\n",
        "\n",
        "    if save:\n",
        "        file_name = f'train_val_loss_{feature_name}_stop_{stop_words}.png'\n",
        "        plt.savefig(os.path.join(IMG_DIR, file_name))\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0PsWfcEJ2F0"
      },
      "source": [
        "def plot_train_val_acc_graph(train_acc_list, val_acc_list, feature_name, stop_words=True, save=True):\n",
        "    x = np.arange(0, NUM_EPOCH)\n",
        "    plt.plot(x, train_acc_list, label=\"train accuracy\")\n",
        "\n",
        "    plt.plot(x, val_acc_list, label=\"val accuracy\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.ylabel(\"accuracy %\")\n",
        "    plt.title(f\"Train & Val Accuracy num {feature_name} Stopwords:{stop_words}\")\n",
        "    plt.legend()\n",
        "\n",
        "    if save:\n",
        "        file_name = f'train_val_acc_{feature_name}_stop_{stop_words}.png'\n",
        "        plt.savefig(os.path.join(IMG_DIR, file_name))\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "WjdfDrdjJ9pE",
        "outputId": "11365e1e-216f-4aba-cbd7-84eb1d87c4ae"
      },
      "source": [
        "plot_train_val_acc_graph(train_acc_list, val_acc_list, 'RNN', stop_words=False, save=True)\n",
        "plot_train_val_loss_graph(train_loss_list, val_loss_list, 'RNN', stop_words=False, save=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA89lAbdepvB"
      },
      "source": [
        "## Testing with Sample news headline from Onion.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-AOmV31jLl_"
      },
      "source": [
        "class_map = {\n",
        "    0: 'not onion (true)',\n",
        "    1: 'onion',\n",
        "    2: 'fake'\n",
        "}"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI9wuXr4jnQ3"
      },
      "source": [
        "def evaluate_text(text, model):\n",
        "    encoded_headline = encode_sentence(text, vocab2index)\n",
        "    encoded_input = np.array([encoded_headline[0]]).astype(np.int32)\n",
        "    sample_tensor = torch.from_numpy(encoded_input).long().cuda()\n",
        "    l = encoded_headline[1]\n",
        "\n",
        "    model.eval()\n",
        "    y_hat = model(sample_tensor, torch.tensor([l]))\n",
        "    pred = torch.max(y_hat, 1)[1].cpu().item()\n",
        "    return class_map[pred]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "McjITt77kDol",
        "outputId": "9017f9a2-6746-4018-9424-eb27ba5937ba"
      },
      "source": [
        "evaluate_text(\"Myanmar envoy to London says military seized embassy in 'coup'\", model)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'not onion (true)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EfZikCRrkLUs",
        "outputId": "7031dcf1-ad15-40b4-b4d2-24f101cf3292"
      },
      "source": [
        "evaluate_text(\"17-Year-Old Asks Friend What It Means When Guy You Like Wants Blanket Pardon\", model)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'onion'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5RnPYQ7Pka3I",
        "outputId": "0f6cb6a4-eb96-4cb9-9b89-3cec5d8ab16c"
      },
      "source": [
        "evaluate_text(\"Hillary's alien baby and 7 other out-of-this-world tabloid tales\", model)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'not onion (true)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRVao4z2k07_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}